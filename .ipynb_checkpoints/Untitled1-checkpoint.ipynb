{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17330238-f184-4fa4-b3b9-6209073b1536",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate_train_data_nltkNaiveBayes(samples, labels, num_word_features, get_features, k=5):\n",
    "    \"\"\"\n",
    "        Description: A function which applies k-fold cross-validation to the training split of the poem dataset,\n",
    "        and outputs the nltk Multinomial Naive Bayes classifier's mean performance scores across the folds, as well\n",
    "        as the variability in f1-scores (standard deviation) across the folds.\n",
    "        Inputs:\n",
    "            - samples ==> a list-of-lists where each sub-list/sample is a list of tokens.\n",
    "            - labels ==> a list of labels corresponding to each training sample.\n",
    "            - num_word_features ==> num of word features to use for each training-split FreqDist.\n",
    "            - get_features ==> a function (e.g. doc_features) that turns tokens into features using the specific number of word features.\n",
    "            - k ==> an integer representing the number of folds to iterate over for k-fold cross-validation \n",
    "        Outputs:\n",
    "            - a dictionary containing keys for the average accuracy, macro-average precision/recall/F1-scores\n",
    "              and f1 standard deviation across the samples\n",
    "    \"\"\"\n",
    "    # Initialize lists of metrics\n",
    "    accuracies = []\n",
    "    macro_avg_precisions = []\n",
    "    macro_avg_recalls = []\n",
    "    macro_avg_f1s = []\n",
    "\n",
    "    # Use Stratified KFold scikit-learn class with k (nr folds): it outputs indices \n",
    "    # Shuffle to reduce impact of specific orderings of the samples\n",
    "    SKFGenerator = StratifiedKFold(n_splits=k, shuffle=True, random_state=3)  # Use random_state for reproducibility and comparison of results\n",
    "\n",
    "    ## LOGGER counting progress made\n",
    "    counter = 1\n",
    "    \n",
    "    # Iterate over the folds using the outputted indices by StratifiedKFold for this dataset\n",
    "    for train_indices, val_indices in SKFGenerator.split(samples, labels):\n",
    "            \n",
    "        # Create train_set and val_set tuple (sample-label) lists for each fold using the stratified k fold's indices.\n",
    "        train_set = [(samples[i], labels[i]) for i in train_indices]\n",
    "        val_set = [(samples[i], labels[i]) for i in val_indices]\n",
    "\n",
    "        train_tokenlists = [(tokenlist) for (tokenlist, label) in train_set]\n",
    "        train_vocabulary_list = flatten_list_of_lists(train_tokenlists)\n",
    "        all_words = nltk.FreqDist(w for w in train_vocabulary_list)\n",
    "        word_features = list(all_words)[:num_word_features]\n",
    "\n",
    "        train_featuresets = [(get_features(doc, word_features), label) for (doc, label) in train_set]\n",
    "        val_featuresets = [(get_features(doc, word_features), label) for (doc, label) in val_set]\n",
    "        \n",
    "        # Train the Naive Bayes Classifier\n",
    "        NBclassifier = nltk.NaiveBayesClassifier.train(train_featuresets)\n",
    "        \n",
    "         # Get the true labels and the predicted labels from the classifier\n",
    "        true = [label for (features, label) in val_featuresets]\n",
    "        pred = [NBclassifier.classify(features) for (features, label) in val_featuresets]\n",
    "\n",
    "        # Calculate the accuracy for this particular fold.\n",
    "        acc = accuracy(NBclassifier , val_featuresets)\n",
    "        accuracies.append(acc)\n",
    "\n",
    "        # Calculate macro_average precision, recall, and f1-score for this fold\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(true, pred, average='macro', zero_division=0) # set to 0 to avoid zero-division error\n",
    "        macro_avg_precisions.append(precision)\n",
    "        macro_avg_recalls.append(recall)\n",
    "        macro_avg_f1s.append(f1)  \n",
    "        # Increment counter for logging outputs\n",
    "        counter += 1\n",
    "        \n",
    "    # Calculate the mean for all metrics across the folds.\n",
    "    mean_accuracy = np.mean(accuracies)\n",
    "    mean_macro_precision = np.mean(macro_avg_precisions)\n",
    "    mean_macro_recall = np.mean(macro_avg_recalls)\n",
    "    mean_macro_f1 = np.mean(macro_avg_f1s)\n",
    "\n",
    "    # Calculate the standard deviation of f1 across the folds\n",
    "    std_macro_f1 = np.std(macro_avg_f1s, ddof=1) # apply Bessel's correction for fold std deviation as this is a small sample, not a pop.\n",
    "    # Calculate the range of macro f1 scores (to put std into context)\n",
    "    range_macro_f1 = np.max(macro_avg_f1s) - np.min(macro_avg_f1s)\n",
    "    print(f\"Number of word features: {num_word_features} --- Macro-Avg F1 standard deviation: {std_macro_f1} --- Macro-Avg F1 Range: {range_macro_f1}\")\n",
    "\n",
    "    return {\n",
    "        \"mean_accuracy\": mean_accuracy,\n",
    "        \"mean_macro_precision\": mean_macro_precision,\n",
    "        \"mean_macro_recall\": mean_macro_recall,\n",
    "        \"mean_macro_f1\": mean_macro_f1,\n",
    "        \"std_macro_f1\": std_macro_f1,\n",
    "        \"range_macro_f1\": range_macro_f1\n",
    "    }\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
