{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92623d25-fe8f-4e9d-b233-36516d9f78ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AFINN Lexicon\n",
    "# Instantiate the lexicon\n",
    "afinn = Afinn()\n",
    "\n",
    "# Adapt the doc_features function to include features containing AFINN sentiment scores\n",
    "def doc_features_with_afinn_sentiment_scores(document, word_features): \n",
    "    # Remove duplicate words from the document (line of poetry)\n",
    "    document_words = set(document) \n",
    "    # Create a features dict to represent the word features\n",
    "    features = {}\n",
    "    # Iterate over the top N vocabulary words (word_features) and create a dict-key for that word, with the dict-value signalling whether the\n",
    "    # word occurs in the document (line of poetry) or not.\n",
    "    # Also add a new key-value pair to the features dictionary indicating the sentiment score of the word in question\n",
    "    for word in word_features:\n",
    "        features[f\"contains({word})\"] = (word in document_words)\n",
    "        features[f\"sentiment_score({word})\"] = afinn.score(word)\n",
    "    return features\n",
    "\n",
    "\"\"\"\n",
    "    A function that takes in a range of values for the different nr of most common words to use as features\n",
    "    and then calculates the accuracies and average f1-scores for each nr of most common words.\n",
    "    In contrast to the `calculate_metrics_for_different_vocab_size_features`, this function\n",
    "    uses `doc_features_with_afinn_sentiment_scores` instead of the `doc_features` function which does\n",
    "    NOT contain sentiment scores for each word feature.\n",
    "\"\"\"\n",
    "def afinn_calculate_metrics_for_different_vocab_size_features(\n",
    "    lowest_num_words_limit, # lower end of range for how many words to use\n",
    "    highest_num_words_limit, # higher end of range for how many words to use\n",
    "    all_words, # the freq dist of words ordered by most common to least common\n",
    "    train_tuples, # training data tuples of form (sample, label)\n",
    "    val_tuples,\n",
    "    step_size=50, # interval size between numbers of words to test\n",
    "):\n",
    "    top_word_counts = np.arange(lowest_num_words_limit, highest_num_words_limit, step_size)\n",
    "    accuracies = [] # store accuracies for each nr of top words used in here\n",
    "    avg_f1_scores = [] # store macro f1 scores for each nr of top words used in here\n",
    "\n",
    "    # iterate over the array of top-word counts to use (i.e. vocab subset to use in features)\n",
    "    for vocab_size in top_word_counts:\n",
    "        print(vocab_size)\n",
    "        # store the list of top \"vocab_size\" words to use\n",
    "        word_features = list(all_words)[:vocab_size]\n",
    "        # get the featuresets based on the top N word features for training and validation splits\n",
    "        train_data_featuresets = [(doc_features_with_afinn_sentiment_scores(doc, word_features), label) for (doc, label) in train_tuples]\n",
    "        validation_data_featuresets = [(doc_features_with_afinn_sentiment_scores(doc, word_features), label) for (doc, label) in val_tuples]\n",
    "        # train a NB classifier and append accuracy score to the above-defined list\n",
    "        NBclassifier = nltk.NaiveBayesClassifier.train(train_data_featuresets)\n",
    "        accuracy = nltk.classify.accuracy(NBclassifier, validation_data_featuresets)\n",
    "        accuracies.append(accuracy)\n",
    "        # # now get the macro avg f1 scores (more complicated)\n",
    "        # # store all the predicted labels here\n",
    "        validation_predictions= []\n",
    "\n",
    "        # iterate over each validation featurset and get the predicted label\n",
    "        for features_dict, label in validation_data_featuresets:\n",
    "            predicted_label = NBclassifier.classify(features_dict)\n",
    "            validation_predictions.append(predicted_label)\n",
    "    \n",
    "        # Retrieve macro-average F1 score from classification report and store it in avg_f1_scores\n",
    "        class_report = classification_report(\n",
    "            original_dataset_validation_labels, \n",
    "            validation_predictions,\n",
    "            output_dict=True,  # Return report as a dictionary (easier to access metrics)\n",
    "            # Set the score to 0 if \"UndefinedMetricWarning\" appears because either recall or precision for a class are 0.0\n",
    "            zero_division=0  \n",
    "        )\n",
    "        \n",
    "        macro_avg_f1 = class_report['macro avg']['f1-score'] \n",
    "        avg_f1_scores.append(macro_avg_f1)\n",
    "    return top_word_counts, accuracies, avg_f1_scores\n",
    "\n",
    "## RUN THE EXPERIMENT AGAIN USING THE WORDNET NEGATION FUNCTION BUT WITH ADDDED AFINN LEXICON SENTIMENT SCORES\n",
    "\n",
    "# Use the wordnet_negated tokens (train and validation) for the vocabulary set\n",
    "vocabulary_list = flatten_list_of_lists(wordnet_negated_train_tokens)\n",
    "vocabulary_set = set(vocabulary_list)\n",
    "# create a freq dist of the words, convert to lower case\n",
    "all_words = nltk.FreqDist(w for w in vocabulary_list)\n",
    "\n",
    "# Get the accuracies and f1 scores for different numbers of word features to use to choose the best nr of word features for the negated sets\n",
    "top_word_counts, accuracies, avg_f1_scores =  afinn_calculate_metrics_for_different_vocab_size_features(\n",
    "                                                                                                    400,\n",
    "                                                                                                    1301,\n",
    "                                                                                                    all_words,\n",
    "                                                                                                    wordnet_negated_train_data_tuples,\n",
    "                                                                                                    wordnet_negated_validation_data_tuples\n",
    "                                                                                                  )\n",
    "# Plot the results\n",
    "plot_word_feature_counts_against_scores(top_word_counts, accuracies, avg_f1_scores, \n",
    "                                        \"Accuracy and Macro Avg F1 Score vs. Vocabulary Size (WordNet Negation with AFINN Sentiment Scores)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff5c21d-04b0-47f5-bb1f-28eb8921a348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SentiWordNet\n",
    "\n",
    "\n",
    "########## CODE ADAPTED FROM: https://medium.com/@nidhikayadav/sentiment-analysis-with-python-sentiwordnet-fd07ffc557 ##############################\n",
    "def get_sentiwordnet_scores_from_tokens(tokens):\n",
    "\n",
    "    # remove bigrams to calculate sentiment score for the document (tokenized line of poetry\n",
    "    tokens_without_bigrams = [token for token in tokens if not isinstance(token, tuple)]        \n",
    "    \n",
    "    pos_tagged_tokens = nltk.pos_tag(tokens_without_bigrams)\n",
    "    \n",
    "    positive_sentiment = 0.0\n",
    "    negative_sentiment = 0.0\n",
    "    \n",
    "    for word_tag_pair in pos_tagged_tokens:\n",
    "        word = word_tag_pair[0]\n",
    "        pos_tag = word_tag_pair[1]\n",
    "        # Convert nltk pos_tags to WordNet format for the most relevant pos tags\n",
    "        if pos_tag.startswith('J'):\n",
    "            pos_tag =  wordnet.ADJ\n",
    "        elif pos_tag.startswith('R'):\n",
    "            pos_tag =  wordnet.ADV    \n",
    "        elif pos_tag.startswith('N'):\n",
    "            pos_tag =  wordnet.NOUN\n",
    "        else:\n",
    "            continue\n",
    "        word_synsets = wordnet.synsets(word, pos=pos_tag)\n",
    "        if not word_synsets:\n",
    "            continue\n",
    "        top_synset = word_synsets[0]\n",
    "        senti_word_net = swn.senti_synset(top_synset.name())\n",
    "        positive_sentiment += senti_word_net.pos_score() \n",
    "        negative_sentiment +=  senti_word_net.neg_score()\n",
    "    return positive_sentiment, negative_sentiment\n",
    "\n",
    "####################################################################################################################################################\n",
    "\n",
    "\n",
    "# Adapt the doc_features function to include features containing SentiWordNet sentiment scores\n",
    "def doc_features_with_swn_sentiment_scores(document, word_features): \n",
    "    \n",
    "    # Get the swn pos and neg summed scores for the document (a list of tokens)\n",
    "    positive_score, negative_score = get_sentiwordnet_scores_from_tokens(document)\n",
    "  \n",
    "    # Remove duplicate words from the document (line of poetry)\n",
    "    document_words = set(document)  \n",
    "    \n",
    "    # Create a features dict to represent the word features\n",
    "    features = {}\n",
    "    # Iterate over the top N vocabulary words (word_features) and create a dict-key for that word, with the dict-value signalling whether the\n",
    "    # word occurs in the document (line of poetry) or not.\n",
    "    # Also add a new key-value pair to the features dictionary indicating the sentiment score of the word in question\n",
    "    for word in word_features:\n",
    "        features[f\"contains({word})\"] = (word in document_words)\n",
    "\n",
    "    # Add features representing swn positive and negative scores\n",
    "    features[\"positive_sentiment\"] = positive_score\n",
    "    features[\"negative_sentiment\"] = negative_score\n",
    "    \n",
    "    return features\n",
    "\n",
    "\"\"\"\n",
    "    A function that takes in a range of values for the different nr of most common words to use as features\n",
    "    and then calculates the accuracies and average f1-scores for each nr of most common words.\n",
    "    In contrast to the `afinn_calculate_metrics_for_different_vocab_size_features`, this function\n",
    "    uses `doc_features_with_swn_sentiment_scores`  instead of the `doc_features_with_afinn_sentiment_scores` function\n",
    "    to use SentiWordNet summed positive and negative scores instead of AFINN sentiment scores.\n",
    "\"\"\"\n",
    "def swn_calculate_metrics_for_different_vocab_size_features(\n",
    "    lowest_num_words_limit, # lower end of range for how many words to use\n",
    "    highest_num_words_limit, # higher end of range for how many words to use\n",
    "    all_words, # the freq dist of words ordered by most common to least common\n",
    "    train_tuples, # training data tuples of form (sample, label)\n",
    "    val_tuples,\n",
    "    step_size=50, # interval size between numbers of words to test\n",
    "):\n",
    "    top_word_counts = np.arange(lowest_num_words_limit, highest_num_words_limit, step_size)\n",
    "    accuracies = [] # store accuracies for each nr of top words used in here\n",
    "    avg_f1_scores = [] # store macro f1 scores for each nr of top words used in here\n",
    "\n",
    "    # iterate over the array of top-word counts to use (i.e. vocab subset to use in features)\n",
    "    for vocab_size in top_word_counts:\n",
    "        print(vocab_size)\n",
    "        # store the list of top \"vocab_size\" words to use\n",
    "        word_features = list(all_words)[:vocab_size]\n",
    "        # get the featuresets based on the top N word features for training and validation splits\n",
    "        train_data_featuresets = [(doc_features_with_swn_sentiment_scores(doc, word_features), label) for (doc, label) in train_tuples]\n",
    "        validation_data_featuresets = [(doc_features_with_swn_sentiment_scores(doc, word_features), label) for (doc, label) in val_tuples]\n",
    "        # train a NB classifier and append accuracy score to the above-defined list\n",
    "        NBclassifier = nltk.NaiveBayesClassifier.train(train_data_featuresets)\n",
    "        accuracy = nltk.classify.accuracy(NBclassifier, validation_data_featuresets)\n",
    "        accuracies.append(accuracy)\n",
    "        # # now get the macro avg f1 scores (more complicated)\n",
    "        # # store all the predicted labels here\n",
    "        validation_predictions= []\n",
    "\n",
    "        # iterate over each validation featurset and get the predicted label\n",
    "        for features_dict, label in validation_data_featuresets:\n",
    "            predicted_label = NBclassifier.classify(features_dict)\n",
    "            validation_predictions.append(predicted_label)\n",
    "    \n",
    "        # Retrieve macro-average F1 score from classification report and store it in avg_f1_scores\n",
    "        class_report = classification_report(\n",
    "            original_dataset_validation_labels, \n",
    "            validation_predictions,\n",
    "            output_dict=True,  # Return report as a dictionary (easier to access metrics)\n",
    "            # Set the score to 0 if \"UndefinedMetricWarning\" appears because either recall or precision for a class are 0.0\n",
    "            zero_division=0  \n",
    "        )\n",
    "        \n",
    "        macro_avg_f1 = class_report['macro avg']['f1-score'] \n",
    "        avg_f1_scores.append(macro_avg_f1)\n",
    "    return top_word_counts, accuracies, avg_f1_scores\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## RUN THE EXPERIMENT AGAIN USING THE WORDNET NEGATION FUNCTION BUT WITH ADDDED SENTIWORDNET LEXICON SENTIMENT SCORES\n",
    "\n",
    "# Use the wordnet_negated tokens (train and validation) for the vocabulary set\n",
    "vocabulary_list = flatten_list_of_lists(wordnet_negated_train_tokens)\n",
    "vocabulary_set = set(vocabulary_list)\n",
    "# create a freq dist of the words, convert to lower case\n",
    "all_words = nltk.FreqDist(w for w in vocabulary_list)\n",
    "\n",
    "# Get the accuracies and f1 scores for different numbers of word features to use to choose the best nr of word features for the negated sets\n",
    "top_word_counts, accuracies, avg_f1_scores =  swn_calculate_metrics_for_different_vocab_size_features(\n",
    "                                                                                                    400,\n",
    "                                                                                                    1301,\n",
    "                                                                                                    all_words,\n",
    "                                                                                                    wordnet_negated_train_data_tuples,\n",
    "                                                                                                    wordnet_negated_validation_data_tuples\n",
    "                                                                                                  )\n",
    "# Plot the results\n",
    "plot_word_feature_counts_against_scores(top_word_counts, accuracies, avg_f1_scores, \n",
    "                                        \"Accuracy and Macro Avg F1 Score vs. Vocabulary Size (WordNet Negation with SentiWordNet Sentiment Scores)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
